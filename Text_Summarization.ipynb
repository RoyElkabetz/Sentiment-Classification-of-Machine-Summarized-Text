{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXTQ9jIfBWiii2B6Y6ZBWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoyElkabetz/Text-Summarization-with-Deep-Learning/blob/main/Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94-50bV31g5A",
        "outputId": "690898e8-a325-4a08-fdd3-5960b665ca46"
      },
      "source": [
        "## uncomment only if running from google.colab\n",
        "# clone the git reposetory\n",
        "!git clone https://github.com/RoyElkabetz/Text-Summarization-with-Deep-Learning\n",
        "# add path to .py files for import\n",
        "import sys\n",
        "sys.path.insert(1, \"/content/Text-Summarization-with-Deep-Learning\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Text-Summarization-with-Deep-Learning'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 95 (delta 52), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (95/95), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ejtaOc71hzT",
        "outputId": "a2f1a02f-5732-4820-855f-e3178829fc8b"
      },
      "source": [
        "## uncomment if you want to mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CniCusU62lza"
      },
      "source": [
        "PATH_DATASET = '/content/gdrive/MyDrive/Datasets/Text/news_summary_more.csv'\n",
        "CHECKPOINT_DIR = '/content/gdrive/MyDrive/Checkpoints'\n",
        "MODEL_NAME = 'LSTM_Text_Summarizer'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZxlt_woxho8",
        "outputId": "8b645b7f-0948-4d0d-bce5-1ff72bf13ede"
      },
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display, clear_output\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchtext.legacy.data as data\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.legacy.data import Field, Dataset, Example, BucketIterator, Iterator\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# from torchtext.datasets import IMDB as the_dataset\n",
        "# from torchtext.datasets import AG_NEWS as the_dataset\n",
        "# import torchtext.data as data\n",
        "# from torchtext.data.utils import get_tokenizer\n",
        "# from torchtext.vocab import build_vocab_from_iterator\n",
        "# from torchtext.data.functional import to_map_style_dataset\n",
        "# from torch.utils.data import DataLoader\n",
        "# from torch.utils.data.dataset import random_split\n",
        "# from torch import nn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'torch {torch.__version__}')\n",
        "print('Device properties:')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    gpu_data = torch.cuda.get_device_properties(0)\n",
        "    gpu_name = gpu_data.name\n",
        "    gpu_mem  = f'{gpu_data.total_memory * 1e-9:.02f} Gb'\n",
        "    print(f'GPU: {gpu_name}\\nMemory: {gpu_mem}')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('CPU')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch 1.9.0+cu102\n",
            "Device properties:\n",
            "CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p6Ut6L0t4fQ"
      },
      "source": [
        "class DataFrameDataset(Dataset):\n",
        "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
        "    \"\"\"Pytorch legacy Dataset: https://pytorch.org/text/_modules/torchtext/data/dataset.html\"\"\"\n",
        "    def __init__(self, examples, fields, filter_pred=None):\n",
        "        \"\"\"\n",
        "        Create a dataset from a pandas dataframe of examples and Fields\n",
        "        Arguments:\n",
        "            examples pd.DataFrame: DataFrame of examples\n",
        "            fields {str: Field}: The Fields to use in this tuple. The\n",
        "                string is a field name, and the Field is the associated field.\n",
        "            filter_pred (callable or None): use only exanples for which\n",
        "                filter_pred(example) is true, or use all examples if None.\n",
        "                Default is None\n",
        "        \"\"\"\n",
        "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
        "        if filter_pred is not None:\n",
        "            self.examples = filter(filter_pred, self.examples)\n",
        "        self.fields = dict(fields)\n",
        "        # Unpack field tuples\n",
        "        for n, f in list(self.fields.items()):\n",
        "            if isinstance(n, tuple):\n",
        "                self.fields.update(zip(n, f))\n",
        "                del self.fields[n]\n",
        "\n",
        "class SeriesExample(Example):\n",
        "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
        "  \n",
        "    @classmethod\n",
        "    def fromSeries(cls, data, fields):\n",
        "        return cls.fromdict(data.to_dict(), fields)\n",
        "\n",
        "    @classmethod\n",
        "    def fromdict(cls, data, fields):\n",
        "        ex = cls()\n",
        "        \n",
        "        for key, field in fields.items():\n",
        "            if key not in data:\n",
        "                raise ValueError(\"Specified key {} was not found in \"\n",
        "                \"the input data\".format(key))\n",
        "            if field is not None:\n",
        "                setattr(ex, key, field.preprocess(data[key]))\n",
        "            else:\n",
        "                setattr(ex, key, data[key])\n",
        "        return ex"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DgDn9Xxy3FqN",
        "outputId": "2dbdba52-1509-4bfe-e47a-7103ce5885fa"
      },
      "source": [
        "data_df = pd.read_csv(PATH_DATASET ,encoding='utf-8')\n",
        "data_df.drop_duplicates(subset=['text'],inplace=True)  # dropping duplicates\n",
        "data_df.dropna(axis=0,inplace=True)  # dropping na\n",
        "data_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDhBVBMb3dp8"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiAmXOc0378W",
        "outputId": "32be9332-4315-402f-e243-0d516a1513c4"
      },
      "source": [
        "## run this if you want to remove stop words from data\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower() # lowercase\n",
        "    text = text.split() # convert have'nt -> have not\n",
        "    for i in range(len(text)):\n",
        "        word = text[i]\n",
        "        if word in contraction_mapping:\n",
        "            text[i] = contraction_mapping[word]\n",
        "    text = \" \".join(text)\n",
        "    text = text.split()\n",
        "    newtext = []\n",
        "    for word in text:\n",
        "        if word not in stop_words:\n",
        "            newtext.append(word)\n",
        "    text = \" \".join(newtext)\n",
        "    text = text.replace(\"'s\",'') # convert your's -> your\n",
        "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
        "    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n",
        "    text = re.sub(r'\\.',' . ',text)\n",
        "    return text\n",
        "\n",
        "sample = \"(hello) hi there .man tiger caller who's that isn't it ? WALL-E\"\n",
        "print(preprocess(sample))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            " hi  . man tiger caller  walle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9I6cfkx5ED3",
        "outputId": "985f9af0-dcc6-460b-b1c4-6f9c9e6c0390"
      },
      "source": [
        "# process the data inplace\n",
        "print('Before preprocessing:\\n {}\\n {}\\n'.format(data_df['headlines'][20], data_df['text'][20]))\n",
        "data_df['cleaned_headlines'] = data_df['headlines'].apply(lambda x: preprocess(x))\n",
        "data_df['cleaned_text'] = data_df['text'].apply(lambda x: preprocess(x))\n",
        "print('After preprocessing:\\n {}\\n {}\\n'.format(data_df['headlines'][20], data_df['text'][20]))\n",
        "print('After preprocessing:\\n {}\\n {}\\n'.format(data_df['cleaned_headlines'][20], data_df['cleaned_text'][20]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before preprocessing:\n",
            " I think the opposition even dreams about me: PM Modi\n",
            " Claiming there is a dearth of ideas among opposition parties, Prime Minister Narendra Modi on Wednesday said, \"The opposition talks only about Modi the whole day, I suspect they even dream about me.\" PM Modi, who was addressing the New India Youth Conclave inâ Surat, added that the opposition parties have only one agenda which is \"Modi\". \n",
            "\n",
            "After preprocessing:\n",
            " I think the opposition even dreams about me: PM Modi\n",
            " Claiming there is a dearth of ideas among opposition parties, Prime Minister Narendra Modi on Wednesday said, \"The opposition talks only about Modi the whole day, I suspect they even dream about me.\" PM Modi, who was addressing the New India Youth Conclave inâ Surat, added that the opposition parties have only one agenda which is \"Modi\". \n",
            "\n",
            "After preprocessing:\n",
            " think opposition even dreams me pm modi\n",
            " claiming dearth ideas among opposition parties prime minister narendra modi wednesday said the opposition talks modi whole day suspect even dream me .  pm modi addressing new india youth conclave in surat added opposition parties one agenda modi . \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceSbOcqp6m-c"
      },
      "source": [
        "data_df.replace('', np.nan, inplace=True)\n",
        "data_df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ndNK3O3J9tTZ",
        "outputId": "bba95254-fae7-48d3-de98-dd1ba3a8b39f"
      },
      "source": [
        "text_word_count = []\n",
        "headlines_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data_df['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data_df['cleaned_headlines']:\n",
        "      headlines_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'cleaned_text':text_word_count, 'cleaned_headlines':headlines_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsdZeXQC-Gw9",
        "outputId": "32409b00-7f9f-4e31-b407-ecd94659e05e"
      },
      "source": [
        "cnt = 0\n",
        "for i in data_df['cleaned_headlines']:\n",
        "    if(len(i.split()) <= 10):\n",
        "        cnt += 1\n",
        "print(cnt / len(data_df['cleaned_headlines']))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9874644164294428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SZHjWgw-NAm"
      },
      "source": [
        "max_text_len = 50\n",
        "max_summary_len = 10"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2IMDGBa--mH"
      },
      "source": [
        "cleaned_text = np.array(data_df['cleaned_text'])\n",
        "cleaned_summary = np.array(data_df['cleaned_headlines'])\n",
        "\n",
        "short_text = []\n",
        "short_summary = []\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_text[i].split()) <= max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df = pd.DataFrame({'text': short_text,'summary': short_summary})"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnJw_BX-AEBv"
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x: '<sos> '+ x + ' <eos>')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Po4j1tATeO"
      },
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# define the text field for the dataset\n",
        "TEXT = data.Field(sequential=True,\n",
        "                  lower=True, \n",
        "                  tokenize=tokenizer,\n",
        "                  init_token='<sos>', \n",
        "                  eos_token='<eos>',\n",
        "                  dtype=torch.long)\n",
        "# define the text field for the dataset\n",
        "SUMMARY = data.Field(sequential=True,\n",
        "                    lower=True, \n",
        "                    tokenize=tokenizer,\n",
        "                    init_token='<sos>', \n",
        "                    eos_token='<eos>',\n",
        "                    dtype=torch.long)\n",
        "#SUMMARY = data.Field(sequential=True, tokenize=tokenizer)\n",
        "# TEXT.build_vocab(my_data, max_size=25000, vectors=\"glove.6B.100d\") \n",
        "#TEXT.build_vocab(my_data, max_size=25000) \n",
        "#SUMMARY.build_vocab(my_data)\n",
        "fields = {'text': TEXT, 'summary': SUMMARY}"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv6xCz8Btxez"
      },
      "source": [
        "train_data, test_data, val_data = DataFrameDataset(df, fields=fields).split(split_ratio=[0.8, 0.1, 0.1])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_l8aWWP0LTr"
      },
      "source": [
        "TEXT.build_vocab(train_data)\n",
        "SUMMARY.build_vocab(train_data) \n",
        "\n",
        "vocab = TEXT.vocab"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "rVqBCyuyvxry",
        "outputId": "14028a21-11fd-4c86-9324-d37e38a9beb9"
      },
      "source": [
        "print(f'Number of train samples: {len(train_data)}')\n",
        "print(f'Number of validation samples: {len(val_data)}')\n",
        "print(f'Number of test samples: {len(test_data)}')\n",
        "\n",
        "# display data samples\n",
        "display(HTML('<h4>Display data samples:</h4>'))\n",
        "n_samples = 2\n",
        "for i in range(n_samples):\n",
        "    print(\"\\nText:\\n \", \" \".join([t for t in train_data.examples[i].text]))\n",
        "    print(\"Tokens:\\n \", [vocab.stoi[t] for t in train_data.examples[i].text])\n",
        "    print(\"Summary:\\n \", \" \".join([t for t in train_data.examples[i].summary]))\n",
        "    print(\"Tokens:\\n \", [vocab.stoi[t] for t in train_data.examples[i].summary])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train samples: 76906\n",
            "Number of validation samples: 9613\n",
            "Number of test samples: 9613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h4>Display data samples:</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Text:\n",
            "  wishing luck wife squash player dipika pallikal upcoming commonwealth games indian wicketkeeper dinesh karthik tweeted to able support wife achieve goals everything me . make memories importantly enjoy moment karthik wrote twitter post wishing wife indian athletes .\n",
            "Tokens:\n",
            "  [3003, 6216, 177, 11419, 342, 11858, 21672, 182, 1962, 549, 14, 2857, 3101, 3932, 79, 896, 697, 357, 177, 2403, 1654, 1696, 520, 4, 126, 7508, 14697, 4178, 1876, 3932, 100, 134, 216, 3003, 177, 14, 3056, 4]\n",
            "Summary:\n",
            "  <sos> support everything karthik wife ahead cwg <eos>\n",
            "Tokens:\n",
            "  [2, 357, 1696, 3932, 177, 391, 5742, 3]\n",
            "\n",
            "Text:\n",
            "  priyanka chopra debut hollywood film baywatch set release india june 2 currently 15 rating american review aggregator site rotten tomatoes . 46 reviews critic consensus states baywatch takes source material jiggle factor rrated levels lacks original campy charm leaves charming stars flailing shallows .\n",
            "Tokens:\n",
            "  [555, 679, 571, 1236, 15, 10684, 137, 219, 7, 421, 110, 358, 247, 3247, 315, 1857, 7457, 1019, 17451, 14404, 4, 2887, 5985, 6125, 11230, 314, 10684, 1834, 1753, 2220, 70529, 7275, 31870, 1928, 11051, 1804, 60761, 13597, 4391, 17805, 958, 43525, 82568, 4]\n",
            "Summary:\n",
            "  <sos> priyanka baywatch gets 15 rating movie review site <eos>\n",
            "Tokens:\n",
            "  [2, 555, 10684, 1972, 247, 3247, 1185, 1857, 1019, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtTxuiLxwJ6J",
        "outputId": "baea24b2-77fc-4cfd-e16e-ab3ddd5dd05a"
      },
      "source": [
        "print(vars(train_data.examples[-1]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['national', 'security', 'adviser', 'ajit', 'doval', 'central', 'vigilance', 'commissioner', 'kv', 'chaudhary', 'interfered', 'corruption', 'investigation', 'cbi', 'special', 'director', 'rakesh', 'asthana', 'cbi', 'officer', 'mk', 'sinha', 'told', 'supreme', 'court', 'monday', '.', 'allow', 'searches', 'important', 'inquiry', 'sinha', 'added', '.', 'sinha', 'also', 'said', 'union', 'minister', 'haribhai', 'parthibhai', 'chaudhary', 'took', 'a', 'crores', 'help', 'businessman', '.'], 'summary': ['<sos>', 'ajit', 'doval', 'interfered', 'probe', 'cbi', 'asthana', 'officer', 'sc', '<eos>']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjzvUwk_xnft"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = Iterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device, \n",
        "    sort_key=lambda x: len(x.text))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZmFkO-q5iKB"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        # initializations\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        # we will use 2 layers for both encoder and decoder\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        return hidden, cell\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        # initialize\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        # for decoder we will use n_directions 1\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        # fully connected layer to predict words\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, hidden, cell):\n",
        "        \n",
        "        #trg = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        trg = trg.unsqueeze(0)\n",
        "        \n",
        "        #trg = [1, batch size]\n",
        "        embedded = self.dropout(self.embedding(trg))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell\n",
        "\n",
        "    \n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size] where src_len is number of tokens in source sentence\n",
        "        #trg = [trg len, batch size] same for trg_len\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim # we don't have trg.shape[-1] here\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        dec_input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(dec_input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            dec_input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O3xrMfU6kPC"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "OUTPUT_DIM = len(SUMMARY.vocab)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "# initialize seq2seq model\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBp1ZBSl61DE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}