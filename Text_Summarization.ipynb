{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNb+9+ExmN6ZfMNkeOFdzVo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2148bb51fd1b407a9f358dbbffe019f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a26e6d8c5ff4bb7b066d9e1b714c4f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ab81ae778d346fbad973d2b0b014434",
              "IPY_MODEL_b31f239b8ca84fa3ad4662454908e397"
            ]
          }
        },
        "3a26e6d8c5ff4bb7b066d9e1b714c4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ab81ae778d346fbad973d2b0b014434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3c89c411b3c04d1da181edde6e68c29b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4124fac8e234d3ebfbed0ffc9cad63c"
          }
        },
        "b31f239b8ca84fa3ad4662454908e397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c3ed35ec87b40d39ef20912e3c7e10a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [36:45&lt;00:00, 220.57s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9acee365c0940918425f506a21eb6c9"
          }
        },
        "3c89c411b3c04d1da181edde6e68c29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4124fac8e234d3ebfbed0ffc9cad63c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c3ed35ec87b40d39ef20912e3c7e10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9acee365c0940918425f506a21eb6c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6afaa31c3a974275923c653865c528ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_83b8dd1eb6fc4dfd84e9b0f80587897a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a63ab65c4d344e038c456a3a35a12c23",
              "IPY_MODEL_0bd8eb7956bd4233939788d0c0a2cb39"
            ]
          }
        },
        "83b8dd1eb6fc4dfd84e9b0f80587897a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a63ab65c4d344e038c456a3a35a12c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_21ff8993bad34161a8a3f34a6bbe7f1d",
            "_dom_classes": [],
            "description": "  3%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 97,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15b526fe3097482dbd3ae76f01610d31"
          }
        },
        "0bd8eb7956bd4233939788d0c0a2cb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d214df0bd57460a836254092067a87f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/97 [00:00&lt;00:11,  8.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7745ed739cc46129fde039120a58a01"
          }
        },
        "21ff8993bad34161a8a3f34a6bbe7f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15b526fe3097482dbd3ae76f01610d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d214df0bd57460a836254092067a87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7745ed739cc46129fde039120a58a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoyElkabetz/Text-Summarization-with-Deep-Learning/blob/main/Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94-50bV31g5A",
        "outputId": "6a303e16-2d03-447f-f0b7-b62599b48d92"
      },
      "source": [
        "## uncomment only if running from google.colab\n",
        "# clone the git reposetory\n",
        "!git clone https://github.com/RoyElkabetz/Text-Summarization-with-Deep-Learning\n",
        "# add path to .py files for import\n",
        "import sys\n",
        "sys.path.insert(1, \"/content/Text-Summarization-with-Deep-Learning\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Text-Summarization-with-Deep-Learning'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 110 (delta 63), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 114.07 KiB | 1.41 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ejtaOc71hzT",
        "outputId": "3e1a2ed1-587f-44e1-c4b8-e5303d8e1f42"
      },
      "source": [
        "## uncomment if you want to mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CniCusU62lza"
      },
      "source": [
        "PATH_DATASET = '/content/gdrive/MyDrive/Datasets/Text/news_summary_more.csv'\n",
        "CHECKPOINT_DIR = '/content/gdrive/MyDrive/Checkpoints'\n",
        "MODEL_NAME = 'LSTM_Text_Summarizer'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZxlt_woxho8",
        "outputId": "00bd84ad-1e11-42b8-8834-7552eee34cd6"
      },
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display, clear_output\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchtext.legacy.data as data\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.legacy.data import Field, Dataset, Example, BucketIterator, Iterator\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# from torchtext.datasets import IMDB as the_dataset\n",
        "# from torchtext.datasets import AG_NEWS as the_dataset\n",
        "# import torchtext.data as data\n",
        "# from torchtext.data.utils import get_tokenizer\n",
        "# from torchtext.vocab import build_vocab_from_iterator\n",
        "# from torchtext.data.functional import to_map_style_dataset\n",
        "# from torch.utils.data import DataLoader\n",
        "# from torch.utils.data.dataset import random_split\n",
        "# from torch import nn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'torch {torch.__version__}')\n",
        "print('Device properties:')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    gpu_data = torch.cuda.get_device_properties(0)\n",
        "    gpu_name = gpu_data.name\n",
        "    gpu_mem  = f'{gpu_data.total_memory * 1e-9:.02f} Gb'\n",
        "    print(f'GPU: {gpu_name}\\nMemory: {gpu_mem}')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('CPU')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch 1.9.0+cu102\n",
            "Device properties:\n",
            "GPU: Tesla K80\n",
            "Memory: 12.00 Gb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p6Ut6L0t4fQ"
      },
      "source": [
        "class DataFrameDataset(Dataset):\n",
        "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
        "    \"\"\"Pytorch legacy Dataset: https://pytorch.org/text/_modules/torchtext/data/dataset.html\"\"\"\n",
        "    def __init__(self, examples, fields, filter_pred=None):\n",
        "        \"\"\"\n",
        "        Create a dataset from a pandas dataframe of examples and Fields\n",
        "        Arguments:\n",
        "            examples pd.DataFrame: DataFrame of examples\n",
        "            fields {str: Field}: The Fields to use in this tuple. The\n",
        "                string is a field name, and the Field is the associated field.\n",
        "            filter_pred (callable or None): use only exanples for which\n",
        "                filter_pred(example) is true, or use all examples if None.\n",
        "                Default is None\n",
        "        \"\"\"\n",
        "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
        "        if filter_pred is not None:\n",
        "            self.examples = filter(filter_pred, self.examples)\n",
        "        self.fields = dict(fields)\n",
        "        # Unpack field tuples\n",
        "        for n, f in list(self.fields.items()):\n",
        "            if isinstance(n, tuple):\n",
        "                self.fields.update(zip(n, f))\n",
        "                del self.fields[n]\n",
        "\n",
        "class SeriesExample(Example):\n",
        "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
        "  \n",
        "    @classmethod\n",
        "    def fromSeries(cls, data, fields):\n",
        "        return cls.fromdict(data.to_dict(), fields)\n",
        "\n",
        "    @classmethod\n",
        "    def fromdict(cls, data, fields):\n",
        "        ex = cls()\n",
        "        \n",
        "        for key, field in fields.items():\n",
        "            if key not in data:\n",
        "                raise ValueError(\"Specified key {} was not found in \"\n",
        "                \"the input data\".format(key))\n",
        "            if field is not None:\n",
        "                setattr(ex, key, field.preprocess(data[key]))\n",
        "            else:\n",
        "                setattr(ex, key, data[key])\n",
        "        return ex"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DgDn9Xxy3FqN",
        "outputId": "b31b0cfb-de58-494f-e00f-10ab0d0dfc29"
      },
      "source": [
        "data_df = pd.read_csv(PATH_DATASET ,encoding='utf-8')\n",
        "data_df.drop_duplicates(subset=['text'],inplace=True)  # dropping duplicates\n",
        "data_df.dropna(axis=0,inplace=True)  # dropping na\n",
        "data_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDhBVBMb3dp8"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiAmXOc0378W",
        "outputId": "c6c32c8b-3ca1-4570-a874-445f4648ada1"
      },
      "source": [
        "## run this if you want to remove stop words from data\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower() # lowercase\n",
        "    text = text.split() # convert have'nt -> have not\n",
        "    for i in range(len(text)):\n",
        "        word = text[i]\n",
        "        if word in contraction_mapping:\n",
        "            text[i] = contraction_mapping[word]\n",
        "    text = \" \".join(text)\n",
        "    text = text.split()\n",
        "    newtext = []\n",
        "    for word in text:\n",
        "        if word not in stop_words:\n",
        "            newtext.append(word)\n",
        "    text = \" \".join(newtext)\n",
        "    text = text.replace(\"'s\",'') # convert your's -> your\n",
        "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
        "    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n",
        "    text = re.sub(r'\\.',' . ',text)\n",
        "    return text\n",
        "\n",
        "sample = \"(hello) hi there .man tiger caller who's that isn't it ? WALL-E\"\n",
        "print(preprocess(sample))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            " hi  . man tiger caller  walle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9I6cfkx5ED3",
        "outputId": "baa5683a-488f-4190-ca16-a1b4d78c227b"
      },
      "source": [
        "# process the data inplace\n",
        "print('Before preprocessing:\\n {}\\n {}\\n'.format(data_df['headlines'][20], data_df['text'][20]))\n",
        "data_df['cleaned_headlines'] = data_df['headlines'].apply(lambda x: preprocess(x))\n",
        "data_df['cleaned_text'] = data_df['text'].apply(lambda x: preprocess(x))\n",
        "print('After preprocessing:\\n {}\\n {}\\n'.format(data_df['headlines'][20], data_df['text'][20]))\n",
        "print('After preprocessing:\\n {}\\n {}\\n'.format(data_df['cleaned_headlines'][20], data_df['cleaned_text'][20]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before preprocessing:\n",
            " I think the opposition even dreams about me: PM Modi\n",
            " Claiming there is a dearth of ideas among opposition parties, Prime Minister Narendra Modi on Wednesday said, \"The opposition talks only about Modi the whole day, I suspect they even dream about me.\" PM Modi, who was addressing the New India Youth Conclave inâ Surat, added that the opposition parties have only one agenda which is \"Modi\". \n",
            "\n",
            "After preprocessing:\n",
            " I think the opposition even dreams about me: PM Modi\n",
            " Claiming there is a dearth of ideas among opposition parties, Prime Minister Narendra Modi on Wednesday said, \"The opposition talks only about Modi the whole day, I suspect they even dream about me.\" PM Modi, who was addressing the New India Youth Conclave inâ Surat, added that the opposition parties have only one agenda which is \"Modi\". \n",
            "\n",
            "After preprocessing:\n",
            " think opposition even dreams me pm modi\n",
            " claiming dearth ideas among opposition parties prime minister narendra modi wednesday said the opposition talks modi whole day suspect even dream me .  pm modi addressing new india youth conclave in surat added opposition parties one agenda modi . \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceSbOcqp6m-c"
      },
      "source": [
        "data_df.replace('', np.nan, inplace=True)\n",
        "data_df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ndNK3O3J9tTZ",
        "outputId": "2c449644-f2aa-4d1e-eea0-164a4e94df06"
      },
      "source": [
        "text_word_count = []\n",
        "headlines_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data_df['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data_df['cleaned_headlines']:\n",
        "      headlines_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'cleaned_text':text_word_count, 'cleaned_headlines':headlines_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsdZeXQC-Gw9",
        "outputId": "14af17a4-4e94-4bd9-9443-d41d11f263ec"
      },
      "source": [
        "cnt = 0\n",
        "for i in data_df['cleaned_headlines']:\n",
        "    if(len(i.split()) <= 10):\n",
        "        cnt += 1\n",
        "print(cnt / len(data_df['cleaned_headlines']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9874644164294428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SZHjWgw-NAm"
      },
      "source": [
        "max_text_len = 50\n",
        "max_summary_len = 10\n",
        "pad_token = ' <pad>'"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2IMDGBa--mH"
      },
      "source": [
        "cleaned_text = np.array(data_df['cleaned_text'])\n",
        "cleaned_summary = np.array(data_df['cleaned_headlines'])\n",
        "\n",
        "short_text = []\n",
        "short_summary = []\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_text[i].split()) <= max_text_len):\n",
        "        padded_cleaned_text = cleaned_text[i] + (max_text_len - len(cleaned_text[i].split())) * pad_token\n",
        "        padded_cleaned_summary = cleaned_summary[i] + (max_summary_len - len(cleaned_summary[i].split())) * pad_token\n",
        "        short_text.append(padded_cleaned_text)\n",
        "        short_summary.append(padded_cleaned_summary)\n",
        "        \n",
        "df = pd.DataFrame({'text': short_text,'summary': short_summary})"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnJw_BX-AEBv"
      },
      "source": [
        "#df['summary'] = df['summary'].apply(lambda x: '<sos> '+ x + ' <eos>')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Po4j1tATeO"
      },
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# define the text field for the dataset\n",
        "TEXT = data.Field(sequential=True,\n",
        "                  lower=True, \n",
        "                  tokenize=tokenizer,\n",
        "                  init_token='<sos>', \n",
        "                  eos_token='<eos>',\n",
        "                  dtype=torch.long)\n",
        "# define the text field for the dataset\n",
        "SUMMARY = data.Field(sequential=True,\n",
        "                    lower=True, \n",
        "                    tokenize=tokenizer,\n",
        "                    init_token='<sos>', \n",
        "                    eos_token='<eos>',\n",
        "                    dtype=torch.long)\n",
        "#SUMMARY = data.Field(sequential=True, tokenize=tokenizer)\n",
        "# TEXT.build_vocab(my_data, max_size=25000, vectors=\"glove.6B.100d\") \n",
        "#TEXT.build_vocab(my_data, max_size=25000) \n",
        "#SUMMARY.build_vocab(my_data)\n",
        "fields = {'text': TEXT, 'summary': SUMMARY}"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv6xCz8Btxez"
      },
      "source": [
        "train_data, test_data, val_data = DataFrameDataset(df, fields=fields).split(split_ratio=[0.8, 0.1, 0.1])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_l8aWWP0LTr",
        "outputId": "68b35612-54d6-48ff-8088-ff633ee5cc3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TEXT.build_vocab(train_data, min_freq=2)\n",
        "SUMMARY.build_vocab(train_data, min_freq=2) \n",
        "\n",
        "vocab = TEXT.vocab\n",
        "print(f\"Unique tokens in training text vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in training summary vocabulary: {len(SUMMARY.vocab)}\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in training text vocabulary: 51536\n",
            "Unique tokens in training summary vocabulary: 21796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "rVqBCyuyvxry",
        "outputId": "8ded81fd-06fe-431e-903e-d59a1e903f20"
      },
      "source": [
        "print(f'Number of train samples: {len(train_data)}')\n",
        "print(f'Number of validation samples: {len(val_data)}')\n",
        "print(f'Number of test samples: {len(test_data)}')\n",
        "\n",
        "# display data samples\n",
        "display(HTML('<h4>Display data samples:</h4>'))\n",
        "n_samples = 2\n",
        "for i in range(n_samples):\n",
        "    print(\"\\nText:\\n \", \" \".join([t for t in train_data.examples[i].text]))\n",
        "    print(\"Tokens:\\n \", [vocab.stoi[t] for t in train_data.examples[i].text])\n",
        "    print(\"Summary:\\n \", \" \".join([t for t in train_data.examples[i].summary]))\n",
        "    print(\"Tokens:\\n \", [vocab.stoi[t] for t in train_data.examples[i].summary])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train samples: 76906\n",
            "Number of validation samples: 9613\n",
            "Number of test samples: 9613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h4>Display data samples:</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Text:\n",
            "  least one person died three people injured portion threestorey building collapsed maharashtra thane friday . many 20 people reported trapped debris rescue operation still process . rescue teams including two national disaster response force teams deployed rescue work . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Tokens:\n",
            "  [172, 21, 308, 251, 45, 11, 303, 5157, 19468, 532, 2055, 341, 4180, 63, 4, 212, 228, 11, 260, 2469, 5276, 1362, 1109, 541, 742, 4, 1362, 1322, 79, 17, 89, 2351, 781, 501, 1322, 1902, 1362, 145, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Summary:\n",
            "  1 dead 3 injured 3storey building collapses thane <pad> <pad>\n",
            "Tokens:\n",
            "  [67, 469, 163, 303, 0, 532, 29805, 4180, 1, 1]\n",
            "\n",
            "Text:\n",
            "  delhi government launched antiencroachment drive wednesday cleared illegal structures built 197 acres public land south delhi asola village officials said . least 100 illegal structures spread across 42 plots valued 3000 crore demolished . several farmhouses boundary walls smallscale mining units built illegally land . <pad> <pad> <pad> <pad> <pad>\n",
            "Tokens:\n",
            "  [31, 12, 199, 29336, 1401, 57, 2134, 767, 4804, 993, 16876, 4854, 183, 629, 157, 31, 0, 700, 91, 5, 4, 172, 231, 767, 4804, 1478, 255, 2348, 9455, 2380, 2359, 28, 7936, 4, 156, 30268, 3479, 4770, 23579, 3703, 2528, 993, 2136, 629, 4, 1, 1, 1, 1, 1]\n",
            "Summary:\n",
            "  197 acres encroached public land cleared south delhi <pad> <pad>\n",
            "Tokens:\n",
            "  [16876, 4854, 30175, 183, 629, 2134, 157, 31, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtTxuiLxwJ6J",
        "outputId": "b131c44c-df77-4223-bef9-4ab6e4f29ead"
      },
      "source": [
        "print(vars(train_data.examples[0])['summary'])\n",
        "print([SUMMARY.vocab.stoi[t] for t in vars(train_data.examples[0])['summary']])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1', 'dead', '3', 'injured', '3storey', 'building', 'collapses', 'thane', '<pad>', '<pad>']\n",
            "[25, 82, 24, 213, 14163, 545, 1355, 3920, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjzvUwk_xnft"
      },
      "source": [
        "BATCH_SIZE = 1\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device,\n",
        "    shuffle=False\n",
        "    )"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvk5S-DDpXBB",
        "outputId": "dde98145-cc94-4e45-a0e8-17572f4e24ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "    trg = batch.summary\n",
        "    if i<10:\n",
        "        print(len(trg))\n",
        "    else:\n",
        "      break\n",
        "        "
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZmFkO-q5iKB"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        # initializations\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        # we will use 2 layers for both encoder and decoder\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        return hidden, cell\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        # initialize\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        # for decoder we will use n_directions 1\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        # fully connected layer to predict words\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, hidden, cell):\n",
        "        \n",
        "        #trg = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        trg = trg.unsqueeze(0)\n",
        "        \n",
        "        #trg = [1, batch size]\n",
        "        embedded = self.dropout(self.embedding(trg))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell\n",
        "\n",
        "    \n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size] where src_len is number of tokens in source sentence\n",
        "        #trg = [trg len, batch size] same for trg_len\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim # we don't have trg.shape[-1] here\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        dec_input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(dec_input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            dec_input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O3xrMfU6kPC",
        "outputId": "10bae506-6f6a-4652-ead8-397628467d00"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "OUTPUT_DIM = len(SUMMARY.vocab)\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "HID_DIM = 64\n",
        "N_LAYERS = 1\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "# initialize seq2seq model\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMJo4oMo7Udu",
        "outputId": "41de53b8-1529-4a93-c6d6-cbb3d20e7b56"
      },
      "source": [
        "vocab.stoi['<pad>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBp1ZBSl61DE"
      },
      "source": [
        "class Seq2Seq_trainer(object):\n",
        "    def __init__(self, model, train_iterator, valid_iterator, pad_index, device, clip, learning_rate):\n",
        "        # initialize config variables\n",
        "        self.model = model.to(device)\n",
        "        self.train_iterator = train_iterator\n",
        "        self.valid_iterator = valid_iterator\n",
        "        self.clip = clip\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        # TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index = pad_index)\n",
        "        self.model.apply(self.init_weights)\n",
        "        print(f'The model has {self.count_parameters(self.model):,} trainable parameters')\n",
        "\n",
        "        \n",
        "    \n",
        "    def init_weights(self,m):\n",
        "        for name, param in m.named_parameters():\n",
        "            nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "    \n",
        "    def count_parameters(self, model):\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    \n",
        "    def train(self):\n",
        "\n",
        "        self.model.train()\n",
        "        epoch_loss = 0\n",
        "        for i, batch in enumerate(self.train_iterator):\n",
        "\n",
        "            src = batch.text\n",
        "            trg = batch.summary\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(src, trg)\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = self.criterion(output, trg)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
        "            self.optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(self.train_iterator)\n",
        "    \n",
        "    \n",
        "    def evaluate(self, iterator):\n",
        "\n",
        "        self.model.eval()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(iterator):\n",
        "\n",
        "                src = batch.text\n",
        "                trg = batch.summary\n",
        "                output = self.model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "                #trg = [trg len, batch size]\n",
        "                #output = [trg len, batch size, output dim]\n",
        "\n",
        "                output_dim = output.shape[-1]\n",
        "                output = output[1:].view(-1, output_dim)\n",
        "                trg = trg[1:].view(-1)\n",
        "\n",
        "                #trg = [(trg len - 1) * batch size]\n",
        "                #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "                loss = self.criterion(output, trg)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        return epoch_loss / len(iterator)\n",
        "    \n",
        "    \n",
        "    def epoch_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "        return elapsed_mins, elapsed_secs\n",
        "    \n",
        "    \n",
        "    def fit(self, nepochs):\n",
        "        best_valid_loss = float('inf')\n",
        "\n",
        "        for epoch in tqdm(range(nepochs)):\n",
        "            start_time = time.time()\n",
        "            train_loss = self.train()\n",
        "            valid_loss = self.evaluate(self.valid_iterator)\n",
        "            end_time = time.time()\n",
        "            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n",
        "\n",
        "            if valid_loss < best_valid_loss:\n",
        "                best_valid_loss = valid_loss\n",
        "                # torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "                print(f'Epoch with best validation loss: {epoch+1:02}')\n",
        "\n",
        "            print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "            print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "            \n",
        "    def predict(self, iterator):\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(tqdm(iterator)):\n",
        "\n",
        "                src = batch.text\n",
        "                trg = batch.summary\n",
        "                output = self.model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "                #trg = [trg len, batch size]\n",
        "                #output = [trg len, batch size, output dim]\n",
        "                \n",
        "                if i == 0:\n",
        "                    outputs = torch.argmax(output, -1)\n",
        "                else:\n",
        "                    outputs = torch.cat((outputs, torch.argmax(output, -1)), -1)\n",
        "                \n",
        "                # outputs = [trg_len, len(iterator)]\n",
        "        return torch.transpose(outputs, 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6mTEVla8u9g",
        "outputId": "7ba53c59-e8f2-4361-8637-eea22bb3af10"
      },
      "source": [
        "# config vaiables\n",
        "pad_index = SUMMARY.vocab.stoi[SUMMARY.pad_token]\n",
        "# initialize trainer\n",
        "trainer = Seq2Seq_trainer(model, train_iterator, valid_iterator, pad_index, device, 1, 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 6,504,190 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "2148bb51fd1b407a9f358dbbffe019f4",
            "3a26e6d8c5ff4bb7b066d9e1b714c4f7",
            "1ab81ae778d346fbad973d2b0b014434",
            "b31f239b8ca84fa3ad4662454908e397",
            "3c89c411b3c04d1da181edde6e68c29b",
            "b4124fac8e234d3ebfbed0ffc9cad63c",
            "3c3ed35ec87b40d39ef20912e3c7e10a",
            "f9acee365c0940918425f506a21eb6c9"
          ]
        },
        "id": "Bel8WuKl9GXO",
        "outputId": "8438feca-3b13-4998-aea0-e4fa125f2a3f"
      },
      "source": [
        "trainer.fit(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2148bb51fd1b407a9f358dbbffe019f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch with best validation loss: 01\n",
            "Epoch: 01 | Time: 2m 3s\n",
            "\tTrain Loss: 6.689 | Train PPL: 803.133\n",
            "\t Val. Loss: 6.395 |  Val. PPL: 598.689\n",
            "Epoch with best validation loss: 02\n",
            "Epoch: 02 | Time: 2m 2s\n",
            "\tTrain Loss: 6.289 | Train PPL: 538.663\n",
            "\t Val. Loss: 6.393 |  Val. PPL: 597.541\n",
            "Epoch: 03 | Time: 2m 2s\n",
            "\tTrain Loss: 6.223 | Train PPL: 504.256\n",
            "\t Val. Loss: 6.405 |  Val. PPL: 604.726\n",
            "Epoch: 04 | Time: 2m 2s\n",
            "\tTrain Loss: 6.164 | Train PPL: 475.372\n",
            "\t Val. Loss: 6.403 |  Val. PPL: 603.850\n",
            "Epoch with best validation loss: 05\n",
            "Epoch: 05 | Time: 2m 2s\n",
            "\tTrain Loss: 6.042 | Train PPL: 420.898\n",
            "\t Val. Loss: 6.247 |  Val. PPL: 516.268\n",
            "Epoch with best validation loss: 06\n",
            "Epoch: 06 | Time: 2m 2s\n",
            "\tTrain Loss: 5.822 | Train PPL: 337.764\n",
            "\t Val. Loss: 6.160 |  Val. PPL: 473.362\n",
            "Epoch with best validation loss: 07\n",
            "Epoch: 07 | Time: 2m 2s\n",
            "\tTrain Loss: 5.654 | Train PPL: 285.362\n",
            "\t Val. Loss: 6.060 |  Val. PPL: 428.256\n",
            "Epoch with best validation loss: 08\n",
            "Epoch: 08 | Time: 2m 2s\n",
            "\tTrain Loss: 5.467 | Train PPL: 236.654\n",
            "\t Val. Loss: 5.982 |  Val. PPL: 396.062\n",
            "Epoch with best validation loss: 09\n",
            "Epoch: 09 | Time: 2m 2s\n",
            "\tTrain Loss: 5.305 | Train PPL: 201.290\n",
            "\t Val. Loss: 5.938 |  Val. PPL: 379.069\n",
            "Epoch with best validation loss: 10\n",
            "Epoch: 10 | Time: 2m 2s\n",
            "\tTrain Loss: 5.171 | Train PPL: 176.026\n",
            "\t Val. Loss: 5.883 |  Val. PPL: 358.754\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr53AzWU9wmo",
        "outputId": "715683f8-9443-4437-a9a3-38b9675bf033"
      },
      "source": [
        "# evaluate on test data\n",
        "test_loss = trainer.evaluate(test_iterator)\n",
        "print(f'\\t Test. Loss: {test_loss:.3f} |  Test. PPL: {math.exp(test_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Test. Loss: 5.871 |  Test. PPL: 354.561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebw98ig1GH4Q"
      },
      "source": [
        "body = '''\n",
        "       Scientists say they have discovered a new species of orangutans on Indonesia’s island of Sumatra.\n",
        "The population differs in several ways from the two existing orangutan species found in Sumatra and the neighboring island of Borneo.\n",
        "The orangutans were found inside North Sumatra’s Batang Toru forest, the science publication Current Biology reported.\n",
        "Researchers named the new species the Tapanuli orangutan. They say the animals are considered a new species because of genetic, skeletal and tooth differences.\n",
        "Michael Kruetzen is a geneticist with the University of Zurich who has studied the orangutans for several years. He said he was excited to be part of the unusual discovery of a new great ape in the present day. He noted that most great apes are currently considered endangered or severely endangered.\n",
        "Gorillas, chimpanzees and bonobos also belong to the great ape species.\n",
        "Orangutan – which means person of the forest in the Indonesian and Malay languages - is the world’s biggest tree-living mammal. The orange-haired animals can move easily among the trees because their arms are longer than their legs. They live more lonely lives than other great apes, spending a lot of time sleeping and eating fruit in the forest.\n",
        "The new study said fewer than 800 of the newly-described orangutans exist. Their low numbers make the group the most endangered of all the great ape species.\n",
        "They live within an area covering about 1,000 square kilometers. The population is considered highly vulnerable. That is because the environment which they depend on is greatly threatened by development.\n",
        "Researchers say if steps are not taken quickly to reduce the current and future threats, the new species could become extinct “within our lifetime.”\n",
        "Research into the new species began in 2013, when an orangutan protection group in Sumatra found an injured orangutan in an area far away from the other species. The adult male orangutan had been beaten by local villagers and died of his injuries. The complete skull was examined by researchers.\n",
        "Among the physical differences of the new species are a notably smaller head and frizzier hair. The Tapanuli orangutans also have a different diet and are found only in higher forest areas.\n",
        "There is no unified international system for recognizing new species. But to be considered, discovery claims at least require publication in a major scientific publication.\n",
        "Russell Mittermeier is head of the primate specialist group at the International Union for the Conservation of Nature. He called the finding a “remarkable discovery.” He said it puts responsibility on the Indonesian government to help the species survive.\n",
        "Matthew Nowak is one of the writers of the study. He told the Associated Press that there are three groups of the Tapanuli orangutans that are separated by non-protected land.He said forest land needs to connect the separated groups.\n",
        "In addition, the writers of the study are recommending that plans for a hydropower center in the area be stopped by the government.\n",
        "It also recommended that remaining forest in the Sumatran area where the orangutans live be protected.\n",
        "I’m Bryan Lynn.\n",
        "\n",
        "        '''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315,
          "referenced_widgets": [
            "6afaa31c3a974275923c653865c528ce",
            "83b8dd1eb6fc4dfd84e9b0f80587897a",
            "a63ab65c4d344e038c456a3a35a12c23",
            "0bd8eb7956bd4233939788d0c0a2cb39",
            "21ff8993bad34161a8a3f34a6bbe7f1d",
            "15b526fe3097482dbd3ae76f01610d31",
            "9d214df0bd57460a836254092067a87f",
            "f7745ed739cc46129fde039120a58a01"
          ]
        },
        "id": "UWREfU4QGVF3",
        "outputId": "6df84f34-9307-41fb-cec0-790f5a2b3911"
      },
      "source": [
        "test_tensor = trainer.predict(test_iterator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6afaa31c3a974275923c653865c528ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=97.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-f589757d1947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-2e45d535996c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# outputs = [trg_len, len(iterator)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 13 and 14 (The offending index is 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmBt-PVVH8Xt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}